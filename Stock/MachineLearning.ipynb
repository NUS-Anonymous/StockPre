{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubun/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "#training Classification\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf',TfidfTransformer()),('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)),])\n",
    "#text_clf = Pipeline([('vect', CountVectorizer()),('tfidf',TfidfTransformer()),('clf', MultinomialNB()),])\n",
    "\n",
    "#Bayes Naive Train Model\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)  \n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Twitter.csv', 'NASA.csv', 'rihanna.csv', 'MoneyUnder30.csv', 'ElonMusk.csv', 'Oprah.csv', 'cnnbrk.csv', 'jtimberlake.csv', 'HillaryClinton.csv', 'Official_Markfb.csv', 'taylorswift13.csv', 'TheEllenShow.csv', 'ladygaga.csv', 'shakira.csv', 'Cristiano.csv', 'realdonaldtrump.csv', 'barackobama.csv', 'jimmyfallon.csv', 'KylieJenner.csv', 'JeffBezos0147.csv', 'BillGates.csv', 'KimKardashian.csv', 'YouTube.csv', 'Ellen.csv', 'Yahoo.csv', 'katyperry.csv', 'JustinTrudeau.csv', 'justinbieber.csv', 'selenagomez.csv', 'ddlovato.csv', 'ArianaGrande.csv']\n"
     ]
    }
   ],
   "source": [
    "path = './TweetsData'\n",
    "extension = 'csv'\n",
    "os.chdir(path)\n",
    "result = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSubString(s,sub):\n",
    "    start = s.find(sub)\n",
    "    end = s.find(' ', start)\n",
    "    if (end ==-1):\n",
    "        end = len(s)\n",
    "    tmp = s[:start] + s[end:]\n",
    "    if (tmp.find(sub)!=-1):\n",
    "        tmp = removeSubString(tmp,sub)\n",
    "    return (tmp)\n",
    "\n",
    "def readFile(fname):\n",
    "    ans = []\n",
    "    with open(fname) as f:\n",
    "        reader = csv.reader(f,delimiter=';')\n",
    "        for row in reader:\n",
    "            tmp = [row[0],row[1],row[2],row[3],row[4]]\n",
    "            ans.append(tmp)\n",
    "    return ans\n",
    "\n",
    "def cleanString(s):\n",
    "    tmp = removeSubString(s,\"http\")\n",
    "    tmp = removeSubString(tmp,\"@\")\n",
    "    tmp = removeSubString(tmp,\"#\")\n",
    "    tmp = removeSubString(tmp,\"&amp\")\n",
    "    tmp = re.sub('[^a-zA-Z ]+', ' ', tmp)\n",
    "    tmp = re.sub( '\\s+', ' ', tmp ).strip()\n",
    "    return tmp.lower()\n",
    "\n",
    "def getCategory(result):\n",
    "    \n",
    "    ans = []\n",
    "    for f in result:\n",
    "        ans = ans+readFile(f)\n",
    "\n",
    "    data = np.array(ans)\n",
    "\n",
    "    tweetL = data[:,4].tolist()\n",
    "    tweetLClean=[]\n",
    "    for i in tweetL:\n",
    "        tmp = cleanString(i)\n",
    "        tweetLClean.append(tmp)\n",
    "    return data,text_clf.predict(tweetLClean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter thanks all who shared on follow the hashtag to see stories behind the profession twitter com i moments\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,predicted = getCategory(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat=twenty_train.target_names\n",
    "tmp=[]\n",
    "for i in predicted:\n",
    "    tmp.append(cat[i])\n",
    "predicted = tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedNP=np.transpose(np.array(predicted))\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "final = np.column_stack((data, predictedNP))\n",
    "\n",
    "\n",
    "# In[10]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04 03:43\n"
     ]
    }
   ],
   "source": [
    "print((final[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime\n",
    "def getWeek(d):\n",
    "    StartDate = date(2016, 1, 4)\n",
    "    end = d\n",
    "    ans = int((end - StartDate).days/7)\n",
    "    return ans \n",
    "def getDay(d):\n",
    "    StartDate = date(2016, 1, 4)\n",
    "    end = d\n",
    "    ans = int((end - StartDate).days)\n",
    "    return ans \n",
    "def convertToDate(s):\n",
    "    return datetime.strptime(s,\"%Y-%m-%d %H:%M\").date()\n",
    "\n",
    "weekList =[]\n",
    "\n",
    "for i in final[:,1]:\n",
    "    weekList.append(getDay(convertToDate(i)))\n",
    "\n",
    "# In[13]:\n",
    "# In[12]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "841"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekDay = np.transpose(np.array(weekList))\n",
    "len(np.unique(weekDay))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numDay = (date(2018,5,4) - date(2016,1,4)).days\n",
    "countTable = list(range(1,numDay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "catList = final[:,5]\n",
    "cat = list(twenty_train.target_names)\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "xMatrix = [[0 for x in range(len(cat))] for y in range(len(countTable))] \n",
    "\n",
    "#xMatrix is 20*Weeks, xMatrix[counTable.index(int)][cat.index(string)]\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "count =0\n",
    "for i in range(len(catList)):\n",
    "    day = int(weekDay[i])\n",
    "    c = catList[i]\n",
    "    if (day not in countTable):\n",
    "        continue;\n",
    "    xMatrix[countTable.index(day)][cat.index(c)]+=1\n",
    "   \n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "normMatrix=[]\n",
    "for r in xMatrix:\n",
    "    total = sum(r)\n",
    "    if (total == 0):\n",
    "        normMatrix.append(r)\n",
    "        continue;\n",
    "    tmp = [i/total for i in r]\n",
    "    normMatrix.append(tmp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubun/Desktop/StockPre\n"
     ]
    }
   ],
   "source": [
    "path = '..'\n",
    "os.chdir(path)\n",
    "print(os.getcwd())\n",
    "with open(\"/home/ubun/Desktop/StockPre/Stock/stock_data/fluctuations/finalFluctuation.txt\") as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.strip() for x in content] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = re.split(':| ',content[0])\n",
    "stocksName = [x.strip() for x in sdf[2::2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "yMatrix = [[0 for x in range(len(countTable))] for y in range(len(stocksName))] \n",
    "#[-1,0,1] with -1 is loss, 0 is neutral, 1 is gain\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(countTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "806"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputEntries = []\n",
    "for x in content:\n",
    "    inputEntries.append(int(x.split(\":\")[0].split(\" \")[1])-2)\n",
    "inputEntries.pop(0)\n",
    "inputEntries.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2.0\n",
    "try: \n",
    "    for i in range(len(content)):\n",
    "        a = re.split(':| ',content[i])\n",
    "        tmp = [x.strip() for x in a[3::2]]\n",
    "        for j in range(len(tmp)):\n",
    "            s = re.sub('[^0-9-.]+', '',tmp[j])\n",
    "            if (s == \"\" or s==\"NAN\"):\n",
    "                n = 0.0\n",
    "            else: \n",
    "                n = float(s)\n",
    "            if (n<=(-1*threshold)):\n",
    "                yMatrix[j][i]= \"Loss\"\n",
    "            elif (n>=threshold):\n",
    "                yMatrix[j][i]= \"Gain\"\n",
    "            else:\n",
    "                yMatrix[j][i]= \"Neutral\"\n",
    "except (IndexError):\n",
    "    print (i)\n",
    "    print (j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete Weekend\n",
    "#remove last row\n",
    "inputs = np.delete(xMatrix,(len(xMatrix)-1),axis=0)\n",
    "#remove first column\n",
    "outputs = np.delete(yMatrix,0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubun/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 20.460599660873413 Secs ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#take relevant inputs\n",
    "yTemp=np.transpose(outputs)\n",
    "fInput=[]\n",
    "fOutPut = []\n",
    "for i in inputEntries:\n",
    "    fInput.append(inputs[i])\n",
    "    fOutPut.append(yTemp[i])\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "fOutPut = np.transpose(np.array(fOutPut))\n",
    "fInput = np.array(fInput)\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('objs.pkl', 'wb') as f: \n",
    "    pickle.dump([fOutPut, fInput,stocksName], f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('objs.pkl','rb') as f:  # Python 3: open(..., 'rb')\n",
    "    fOutPut, fInput,stocksName = pickle.load(f)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubun/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.3089878559112549 Secs ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#building SVM for each stock\n",
    "#row\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "index = -1\n",
    "pickedStock = [\"BDX\",\"GOOGL\",\"PGR\",\"JNJ\",\"CSCO\",\"CLX\",\"PG\",\"MSFT\",\"CHKP\",\"ORCL\",\"DIS\",\"SAFT\",\"ITC\",\n",
    "              \"KO\",\"WMT\",\"VZ\",\"TRV\",\"MCD\",\"COST\"]\n",
    "for stock in fOutPut:\n",
    "    index +=1\n",
    "    if (stocksName[index] not in pickedStock):\n",
    "        continue;\n",
    "        \n",
    "    clf = svm.SVC(decision_function_shape='ovo',kernel='sigmoid')\n",
    "    scores = cross_val_score(clf, fInput, stock, cv=5)\n",
    "    #print stock Name\n",
    "    \n",
    "    file.write (stocksName[index]+\"\\n\")\n",
    "    file.write(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)+\"\\n\")\n",
    "    file.write (\"\\n\")\n",
    "file.close() \n",
    "print(\"--- %s Secs ---\" % (time.time() - start_time))\n",
    "#working up till here\n",
    "\n",
    "\n",
    "# In[ ]\n",
    "path = './Stock'\n",
    "os.chdir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exit main thread\n",
      "--- 3.5818567276000977 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import Exporter\n",
    "import os.path\n",
    "import got3\n",
    "import codecs\n",
    "from threading import Thread\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "start_time = time.time()\n",
    "def getData(name,startObj,endObj):\n",
    "#     print (\"getting Data\")\n",
    "    start = startObj.strftime('%Y-%m-%d')\n",
    "    end = endObj.strftime('%Y-%m-%d')\n",
    "    tweetCriteria = got3.manager.TweetCriteria().setUsername(name).setSince(start).setUntil(end).setMaxTweets(0)\n",
    "    tweet = got3.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "    outputFileName = \"Prediction/%s.csv\"%(name)\n",
    "    outputFile = codecs.open(outputFileName, \"a\", \"utf-8\")\n",
    "    for t in tweet:\n",
    "        outputFile.write(('%s;%s;%d;%d;\"%s\"\\n' % (outputFileName,t.date.strftime(\"%Y-%m-%d %H:%M\"), t.retweets, t.favorites, t.text)))\n",
    "    outputFile.flush()\n",
    "\n",
    "ppl=[\"BillGates\",\"realdonaldtrump\",\"Ellen\",\"ElonMusk\",\"barackobama\",\"katyperry\",'justinbieber','rihanna',\n",
    "    'ladygaga','taylorswift13','TheEllenShow','Cristiano','YouTube','jtimberlake','Twitter','KimKardashian',\n",
    "    'ArianaGrande','ddlovato','selenagomez','cnnbrk','shakira','jimmyfallon','HillaryClinton',\n",
    "    'JeffBezos0147','JustinTrudeau','KylieJenner','Official_Markfb','MoneyUnder30','NASA','Oprah','Yahoo']\n",
    "\n",
    "\n",
    "threads=[]\n",
    "for p in ppl:\n",
    "    t = Thread(target = getData, args = (p,date(2018,5,6),date(2018,5,7),)) \n",
    "    threads.append(t)\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "print(\"Exit main thread\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Twitter.csv', 'NASA.csv', 'rihanna.csv', 'MoneyUnder30.csv', 'ElonMusk.csv', 'Oprah.csv', 'cnnbrk.csv', 'jtimberlake.csv', 'HillaryClinton.csv', 'Official_Markfb.csv', 'taylorswift13.csv', 'TheEllenShow.csv', 'ladygaga.csv', 'shakira.csv', 'Cristiano.csv', 'realdonaldtrump.csv', 'barackobama.csv', 'jimmyfallon.csv', 'KylieJenner.csv', 'JeffBezos0147.csv', 'BillGates.csv', 'KimKardashian.csv', 'YouTube.csv', 'Ellen.csv', 'Yahoo.csv', 'katyperry.csv', 'JustinTrudeau.csv', 'justinbieber.csv', 'selenagomez.csv', 'ddlovato.csv', 'ArianaGrande.csv']\n"
     ]
    }
   ],
   "source": [
    "path = './Prediction'\n",
    "extension = 'csv'\n",
    "os.chdir(path)\n",
    "result = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
